{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('train.csv')\n",
    "df = df.drop(['Name', 'Embarked', 'Ticket'], 1)\n",
    "df.fillna(0, inplace=True)\n",
    "df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
    "\n",
    "all_cabins = df['Cabin'].tolist()\n",
    "all_cabins_set = set(all_cabins)\n",
    "cabins_map = {}\n",
    "x = 0\n",
    "for cabin in all_cabins_set:\n",
    "    cabins_map[cabin] = x\n",
    "    x += 1\n",
    "    \n",
    "df['Cabin'] = df['Cabin'].map(cabins_map)\n",
    "df = df.astype('float32')\n",
    "\n",
    "labels = df['Survived']\n",
    "labels = (np.arange(2) == (df['Survived'])[:,None]).astype(np.float32)\n",
    "df = df.drop(['Survived'], 1)\n",
    "train_data = np.array(df[:800])\n",
    "test_data = np.array(df[800:])\n",
    "train_labels = labels[:800]\n",
    "test_labels = labels[800:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized variables.\n",
      "Epoch: 1000 Accuracy: 0.83375 Loss: 0.3867849\n",
      "Epoch: 2000 Accuracy: 0.8475 Loss: 0.34049034\n",
      "Epoch: 3000 Accuracy: 0.85375 Loss: 0.32300586\n",
      "Epoch: 4000 Accuracy: 0.8675 Loss: 0.30987975\n",
      "Epoch: 5000 Accuracy: 0.8675 Loss: 0.2986021\n",
      "Epoch: 6000 Accuracy: 0.87875 Loss: 0.2894581\n",
      "Epoch: 7000 Accuracy: 0.88375 Loss: 0.28169134\n",
      "Epoch: 8000 Accuracy: 0.8875 Loss: 0.27664688\n",
      "Epoch: 9000 Accuracy: 0.8775 Loss: 0.27629894\n",
      "Epoch: 10000 Accuracy: 0.89625 Loss: 0.26716456\n",
      "Epoch: 11000 Accuracy: 0.89 Loss: 0.2680417\n",
      "Epoch: 12000 Accuracy: 0.89125 Loss: 0.25880075\n",
      "Epoch: 13000 Accuracy: 0.8975 Loss: 0.2528423\n",
      "Epoch: 14000 Accuracy: 0.8975 Loss: 0.25708652\n",
      "Test accuracy: 0.8131868\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "num_classes = 2\n",
    "data_size = 8\n",
    "learning_rate = 0.002\n",
    "epochs = 15000\n",
    "\n",
    "def randomize(dataset, labels):\n",
    "    permutation = np.random.permutation(labels.shape[0])\n",
    "    shuffled_dataset = dataset[permutation, :]\n",
    "    shuffled_labels = labels[permutation]\n",
    "    return shuffled_dataset, shuffled_labels\n",
    "\n",
    "def nn_model(data, weights, biases):\n",
    "    layer_1 = tf.matmul(data, weights['lay1']) + biases['lay1']\n",
    "    relu = tf.nn.relu(layer_1)\n",
    "    relu_d = tf.nn.dropout(relu, pkeep)\n",
    "    layer_2 = tf.matmul(relu_d, weights['lay2']) + biases['lay2']\n",
    "    return layer_2\n",
    "\n",
    "def accuracy(predicitions, labels):\n",
    "    return 100 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1)) / predictions.shape[0]\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    \n",
    "    with tf.name_scope('Input'):\n",
    "        tf_train_data = tf.placeholder(tf.float32, shape=(None, data_size), name='passengers')\n",
    "        tf_train_labels = tf.placeholder(tf.float32, shape=(None, num_classes), name='labels')\n",
    "        tf_test_data = tf.constant(test_data, name='test_passengers')\n",
    "        pkeep = tf.placeholder(tf.float32, name=\"pkeep\")\n",
    "    \n",
    "    with tf.name_scope('Layers'):\n",
    "        weights = {\n",
    "            'lay1': tf.Variable(tf.truncated_normal([data_size, 100], stddev=0.1), name='weights1'),\n",
    "            'lay2': tf.Variable(tf.truncated_normal([100, num_classes], stddev=0.1), name='weights2')\n",
    "        }\n",
    "\n",
    "        biases = {\n",
    "            #Important to not define initial biases being passed to relu as zeros to prevent the \"dying relu\" problem \n",
    "            'lay1': tf.Variable((tf.ones([100])/10), name='biases1'), \n",
    "            'lay2': tf.Variable(tf.zeros([num_classes]), name='biases2')\n",
    "        }\n",
    "\n",
    "        logits = nn_model(tf_train_data, weights, biases)\n",
    "        \n",
    "    with tf.name_scope('Loss'):\n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=tf_train_labels)) \n",
    "        tf.summary.scalar('loss', loss)\n",
    "    \n",
    "    with tf.name_scope('Optimizer'):\n",
    "        #AdamOptimizer yields better results but GDOptimizer yields better visualization of weights, why?\n",
    "        #Also need to learn more about how these optimizers work \n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss) \n",
    "    \n",
    "    with tf.name_scope('Evaluation'):\n",
    "        train_prediction = tf.nn.softmax(logits) ### Think about renaming this \n",
    "        correct_prediction = tf.equal(tf.argmax(train_prediction,1), tf.argmax(tf_train_labels, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "#         tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    #For tensorboard\n",
    "#     train_writer = tf.summary.FileWriter(os.path.join(DIR, 'train'), sess.graph)\n",
    "#     test_writer = tf.summary.FileWriter(os.path.join(DIR, 'test'), sess.graph)\n",
    "#     summary_op = tf.summary.merge_all()\n",
    "    \n",
    "    #Training model\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('Initialized variables.')\n",
    "    with tf.name_scope('training'):\n",
    "        for epoch in range(1,epochs):\n",
    "            train_data, train_labels = randomize(train_data, train_labels)\n",
    "            _ = sess.run(optimizer, feed_dict={tf_train_data: train_data, tf_train_labels: train_labels, pkeep: 0.70})\n",
    "            \n",
    "            if (epoch % 1000 == 0):\n",
    "                print('Epoch: ' + str(epoch) + ' Accuracy: ' + str(sess.run(accuracy, feed_dict={tf_train_data: train_data, tf_train_labels: train_labels, pkeep: 1.0})) + ' Loss: ' + str(sess.run(loss, feed_dict={tf_train_data: train_data, tf_train_labels: train_labels, pkeep: 1.0})))\n",
    "        \n",
    "        #Need to figure out how to correctly display test data results in an informative way on tensorboard\n",
    "        print('Test accuracy: ' + str(sess.run(accuracy, feed_dict={tf_train_data: test_data, tf_train_labels: test_labels, pkeep: 1.0})))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
