# MNIST

Basic Tensorflow Neural Network using the MNIST dataset

Data: https://www.kaggle.com/competitions/digit-recognizer/data

Accuracy: 0.97757

The training data I used is from the Digit Recognizer Kaggle competition. Right now I'm just using a
5-layer neural network with dropout. In the future I want to implement learning rate decay on this model to see how well that improves my model.

Ultimately I would like to get practice on other deep learning algorithms so I could run this dataset through a CNN. I actually have the
model ready to run, however, I currently lack the computing power to train it.

10/26/23 Update: Github reorg. This was from 2018, just added the link to the dataset.

10/30/23 Update: Implemented MNIST from scratch and added it here instead of creating a new folder in the repo for it.
